{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from bayesian_torch.layers import Conv2dFlipout, LinearFlipout\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主要参数设置\n",
    "epochs = 5\n",
    "complex_cost = 1e-5\n",
    "batch_size = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取样本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(344, 1, 32768, 2)\n",
      "(344, 1)\n",
      "Training set size: 275\n",
      "Testing set size: 69\n"
     ]
    }
   ],
   "source": [
    "signals = np.load('signals.npy')\n",
    "labels = np.load('time_labels.npy')\n",
    "signals = signals.transpose(0,2,1)\n",
    "\n",
    "signals = signals[:,np.newaxis,:,:]\n",
    "labels = labels[:, np.newaxis]\n",
    "print(signals.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "test_size = 0.2  # 测试集比例\n",
    "random_state = 42\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(signals, labels, test_size=test_size, random_state=random_state)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianLargeKernelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size, dilation_rate=1, reduction_ratio=16):\n",
    "        super(BayesianLargeKernelAttention, self).__init__()\n",
    "        \n",
    "        self.kl_divergence = 0.0\n",
    "        # 贝叶斯深度卷积\n",
    "        self.depthwise_conv = Conv2dFlipout(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=in_channels,\n",
    "            kernel_size=(kernel_size, 1),\n",
    "            stride=(1, 1),\n",
    "            padding=2,\n",
    "            groups=in_channels,\n",
    "            prior_variance=0.1\n",
    "        )\n",
    "        \n",
    "        # 贝叶斯深度膨胀卷积\n",
    "        self.dilated_conv = Conv2dFlipout(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=in_channels,\n",
    "            kernel_size=(7, 1),\n",
    "            stride=(1, 1),\n",
    "            padding=9,\n",
    "            groups=in_channels,\n",
    "            prior_variance=0.1,\n",
    "            bias=True\n",
    "        )\n",
    "        \n",
    "        # 贝叶斯逐点卷积\n",
    "        self.pointwise_conv = Conv2dFlipout(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=in_channels // reduction_ratio,\n",
    "            kernel_size=1,\n",
    "            stride=(1, 1),\n",
    "            prior_variance=0.1,\n",
    "            bias=True\n",
    "        )\n",
    "        \n",
    "        # 1×1卷积核获得注意力权重\n",
    "        self.attention_conv = Conv2dFlipout(\n",
    "            in_channels=in_channels // reduction_ratio,\n",
    "            out_channels=in_channels,\n",
    "            kernel_size=1\n",
    "        )\n",
    "        \n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        kl_total = 0.0\n",
    "        x_depthwise, cur_kl = self.depthwise_conv(x)\n",
    "        kl_total += cur_kl\n",
    "        x_dilated, cur_kl = self.dilated_conv(x_depthwise)\n",
    "        kl_total += cur_kl\n",
    "        x_pointwise, cur_kl = self.pointwise_conv(x_dilated)\n",
    "        kl_total += cur_kl\n",
    "        attention_weights, cur_kl = self.attention_conv(x_pointwise)  \n",
    "        kl_total += cur_kl     \n",
    "        attention_weights = self.sigmoid(self.bn(attention_weights))\n",
    "        batch, channel, height, width = x.shape\n",
    "        attention_weights = nn.functional.interpolate(attention_weights, size=(height, width), mode='bilinear')\n",
    "        attended_features = x * attention_weights\n",
    "        self.kl_divergence += kl_total\n",
    "        \n",
    "        return attended_features\n",
    "\n",
    "class regressor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(regressor, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = LinearFlipout(in_channels, 100)\n",
    "        self.linear2 = LinearFlipout(100, out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.kl_divergence = 0.0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        kl_total = 0.0\n",
    "        x = self.flatten(x)\n",
    "        x, cur_kl = self.linear1(x)\n",
    "        kl_total += cur_kl\n",
    "        x, cur_kl = self.linear2(x)\n",
    "        kl_total += cur_kl\n",
    "        x = self.relu(x)\n",
    "        self.kl_divergence += kl_total\n",
    "        return x\n",
    "\n",
    "class BLKAN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=1):\n",
    "        super(BLKAN, self).__init__()\n",
    "        \n",
    "        # 特征提取\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 24, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0)),\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(5, 1), stride=(5, 1)),\n",
    "            BayesianLargeKernelAttention(24, kernel_size=5, dilation_rate=3),\n",
    "            nn.AvgPool2d(kernel_size=(5, 1), stride=(5, 1)),\n",
    "\n",
    "            BayesianLargeKernelAttention(24, kernel_size=5, dilation_rate=3),\n",
    "            nn.AvgPool2d(kernel_size=(5, 1), stride=(5, 1)),\n",
    "\n",
    "            BayesianLargeKernelAttention(24, kernel_size=5, dilation_rate=3),\n",
    "            nn.AvgPool2d(kernel_size=(5, 1), stride=(5, 1)),\n",
    "\n",
    "            BayesianLargeKernelAttention(24, kernel_size=7, dilation_rate=3),\n",
    "            nn.AvgPool2d(kernel_size=(5, 1), stride=(5, 1)),\n",
    "\n",
    "            BayesianLargeKernelAttention(24, kernel_size=5, dilation_rate=3)\n",
    "        )\n",
    "\n",
    "        # 回归分析\n",
    "        self.regressor = regressor(480, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        flattened_features = torch.cat([features.view(features.size(0), -1)], dim=1)\n",
    "        output = self.regressor(flattened_features)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def elbo_loss(model, x, y, num_samples=3):\n",
    "    mse_loss_fn = nn.MSELoss(reduction='sum')\n",
    "    kl_divergence = 0\n",
    "\n",
    "    total_mse = 0\n",
    "    for _ in range(num_samples):\n",
    "        output = model(x)\n",
    "        total_mse += mse_loss_fn(output, y)\n",
    "    \n",
    "    # 计算 KL 散度\n",
    "    for module in model.modules():\n",
    "        if hasattr(module, 'kl_divergence'):\n",
    "            kl_divergence += module.kl_divergence\n",
    "            module.kl_divergence = 0.0\n",
    "            print(module.kl_divergence)\n",
    "\n",
    "    nll = total_mse / num_samples\n",
    "    elbo = nll + kl_divergence / num_samples / batch * complex_cost  # 调整复杂性成本权重\n",
    "    return elbo\n",
    "\n",
    "# 初始化模型和优化器\n",
    "model = BLKAN(num_classes=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  14%|█▍        | 1/7 [00:58<05:49, 58.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  29%|██▊       | 2/7 [01:58<04:53, 58.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  43%|████▎     | 3/7 [02:57<03:55, 58.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  57%|█████▋    | 4/7 [03:59<02:59, 59.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  71%|███████▏  | 5/7 [05:00<02:00, 60.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  86%|████████▌ | 6/7 [06:00<01:00, 60.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 7/7 [06:52<00:00, 58.90s/it]\n",
      "Epoch 2/5:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 5.1452\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  14%|█▍        | 1/7 [01:00<06:03, 60.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  29%|██▊       | 2/7 [02:00<05:01, 60.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  43%|████▎     | 3/7 [03:02<04:03, 60.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  57%|█████▋    | 4/7 [04:02<03:02, 60.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  71%|███████▏  | 5/7 [05:03<02:01, 60.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  86%|████████▌ | 6/7 [06:03<01:00, 60.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 7/7 [06:54<00:00, 59.14s/it]\n",
      "Epoch 3/5:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 3.7495\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  14%|█▍        | 1/7 [00:58<05:52, 58.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  29%|██▊       | 2/7 [01:58<04:55, 59.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  43%|████▎     | 3/7 [02:59<03:57, 59.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  57%|█████▋    | 4/7 [03:58<02:58, 59.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  71%|███████▏  | 5/7 [04:59<01:59, 59.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  86%|████████▌ | 6/7 [05:58<00:59, 59.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 7/7 [06:48<00:00, 58.39s/it]\n",
      "Epoch 4/5:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 3.2148\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  14%|█▍        | 1/7 [00:59<05:58, 59.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  29%|██▊       | 2/7 [01:58<04:57, 59.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  43%|████▎     | 3/7 [02:56<03:56, 59.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  57%|█████▋    | 4/7 [03:56<02:57, 59.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  71%|███████▏  | 5/7 [04:55<01:58, 59.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  86%|████████▌ | 6/7 [05:55<00:59, 59.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 7/7 [06:46<00:00, 58.03s/it]\n",
      "Epoch 5/5:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 3.1048\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  14%|█▍        | 1/7 [01:00<06:04, 60.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  29%|██▊       | 2/7 [01:59<05:01, 60.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  43%|████▎     | 3/7 [02:58<03:59, 59.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  57%|█████▋    | 4/7 [03:58<02:59, 59.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  71%|███████▏  | 5/7 [04:57<01:59, 59.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  86%|████████▌ | 6/7 [05:58<00:59, 59.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 7/7 [06:48<00:00, 58.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 3.0806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, optimizer, num_epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_x, batch_y in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            optimizer.zero_grad()\n",
    "            loss = elbo_loss(model, batch_x, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "train_model(model, train_loader, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试并计算不确定度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: Mean Prediction = [[0.42428714]\n",
      " [0.4157982 ]\n",
      " [0.40506482]\n",
      " [0.4219145 ]\n",
      " [0.41825202]\n",
      " [0.43552005]\n",
      " [0.41913083]\n",
      " [0.4236773 ]\n",
      " [0.41429615]\n",
      " [0.44044605]\n",
      " [0.42041877]\n",
      " [0.39153376]\n",
      " [0.36743584]\n",
      " [0.41366485]\n",
      " [0.42786035]\n",
      " [0.3961564 ]\n",
      " [0.3863121 ]\n",
      " [0.42643124]\n",
      " [0.43319622]\n",
      " [0.39831933]\n",
      " [0.41711932]\n",
      " [0.41009358]\n",
      " [0.42167482]\n",
      " [0.39797807]\n",
      " [0.42978978]\n",
      " [0.41676602]\n",
      " [0.41054633]\n",
      " [0.45424262]\n",
      " [0.4297251 ]\n",
      " [0.40934327]\n",
      " [0.41075104]\n",
      " [0.40923366]\n",
      " [0.42754886]\n",
      " [0.42552796]\n",
      " [0.40106693]\n",
      " [0.4034327 ]\n",
      " [0.43090492]\n",
      " [0.4305793 ]\n",
      " [0.41415742]\n",
      " [0.40676853]], Variance = [[0.00515517]\n",
      " [0.00632663]\n",
      " [0.00429259]\n",
      " [0.006656  ]\n",
      " [0.00428488]\n",
      " [0.00633378]\n",
      " [0.00419422]\n",
      " [0.00565914]\n",
      " [0.00750319]\n",
      " [0.00650128]\n",
      " [0.0062028 ]\n",
      " [0.00557311]\n",
      " [0.0035007 ]\n",
      " [0.00590376]\n",
      " [0.00648958]\n",
      " [0.00469124]\n",
      " [0.00594695]\n",
      " [0.00730249]\n",
      " [0.00684249]\n",
      " [0.00623543]\n",
      " [0.00511617]\n",
      " [0.0063838 ]\n",
      " [0.00622635]\n",
      " [0.00709957]\n",
      " [0.00426448]\n",
      " [0.00596195]\n",
      " [0.00505201]\n",
      " [0.00505636]\n",
      " [0.00661282]\n",
      " [0.00665393]\n",
      " [0.0057721 ]\n",
      " [0.00603361]\n",
      " [0.00620721]\n",
      " [0.00650125]\n",
      " [0.00672223]\n",
      " [0.00582415]\n",
      " [0.00849052]\n",
      " [0.00501347]\n",
      " [0.00425793]\n",
      " [0.0080377 ]]\n",
      "Sample 1: Mean Prediction = [[0.42320386]\n",
      " [0.42649972]\n",
      " [0.4103215 ]\n",
      " [0.40620816]\n",
      " [0.4046384 ]\n",
      " [0.41991127]\n",
      " [0.4117568 ]\n",
      " [0.41072795]\n",
      " [0.37441114]\n",
      " [0.40105206]\n",
      " [0.39553797]\n",
      " [0.40457886]\n",
      " [0.43983555]\n",
      " [0.3917028 ]\n",
      " [0.37693688]\n",
      " [0.4265877 ]\n",
      " [0.40564263]\n",
      " [0.40902668]\n",
      " [0.41537684]\n",
      " [0.42321664]\n",
      " [0.44159082]\n",
      " [0.4025087 ]\n",
      " [0.44890413]\n",
      " [0.37780446]\n",
      " [0.41814312]\n",
      " [0.4173433 ]\n",
      " [0.38620713]\n",
      " [0.3957895 ]\n",
      " [0.40546834]], Variance = [[0.00809253]\n",
      " [0.00363573]\n",
      " [0.00485373]\n",
      " [0.00527997]\n",
      " [0.00702305]\n",
      " [0.00556244]\n",
      " [0.00528673]\n",
      " [0.00376887]\n",
      " [0.00771835]\n",
      " [0.00580853]\n",
      " [0.00404394]\n",
      " [0.00552077]\n",
      " [0.00663342]\n",
      " [0.00708754]\n",
      " [0.00567756]\n",
      " [0.00537923]\n",
      " [0.00493959]\n",
      " [0.00415554]\n",
      " [0.00694389]\n",
      " [0.00517208]\n",
      " [0.00546612]\n",
      " [0.00571691]\n",
      " [0.00515322]\n",
      " [0.00447618]\n",
      " [0.00679103]\n",
      " [0.00522913]\n",
      " [0.00813772]\n",
      " [0.00529033]\n",
      " [0.0074502 ]]\n"
     ]
    }
   ],
   "source": [
    "def predict_with_uncertainty(model, test_loader, num_samples=50):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_x, _ in test_loader:\n",
    "            batch_predictions = []\n",
    "            for _ in range(num_samples):\n",
    "                output = model(batch_x)\n",
    "                batch_predictions.append(output.numpy())\n",
    "            batch_predictions = np.stack(batch_predictions, axis=0)\n",
    "            mean_prediction = batch_predictions.mean(axis=0)\n",
    "            var_prediction = batch_predictions.var(axis=0)\n",
    "            predictions.append((mean_prediction, var_prediction))\n",
    "    return predictions\n",
    "\n",
    "predictions = predict_with_uncertainty(model, test_loader)\n",
    "\n",
    "# 解析预测结果\n",
    "for i, (mean_pred, var_pred) in enumerate(predictions):\n",
    "    print(f'Sample {i}: Mean Prediction = {mean_pred}, Variance = {var_pred}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
